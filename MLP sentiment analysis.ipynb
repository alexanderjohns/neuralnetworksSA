{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\johns\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\johns\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\johns\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\johns\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\johns\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['sentiment'] = df['sentiment'].replace({'negative' : 0, 'positive' : 1})\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text = text.lower()\n",
    "    # split into tokens by white space\n",
    "    tokens = text.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "df['review'] = df['review'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv_unigrams = CountVectorizer(analyzer='word',\n",
    "                              tokenizer=dummy_fun,\n",
    "                              preprocessor=dummy_fun,\n",
    "                              max_features =100000,\n",
    "                              token_pattern=None)\n",
    "\n",
    "\n",
    "cv_bigrams = CountVectorizer(analyzer='word',\n",
    "                              tokenizer=dummy_fun,\n",
    "                              preprocessor=dummy_fun,\n",
    "                              max_features =100000,\n",
    "                              token_pattern=None, ngram_range=(1,2))\n",
    "\n",
    "cv_trigrams = CountVectorizer(analyzer='word',\n",
    "                              tokenizer=dummy_fun,\n",
    "                              preprocessor=dummy_fun,\n",
    "                              max_features =100000,\n",
    "                              token_pattern=None, ngram_range =(1,3))\n",
    "\n",
    "tfidf_unigrams =  TfidfVectorizer(analyzer='word',\n",
    "                              tokenizer=dummy_fun,\n",
    "                              preprocessor=dummy_fun,\n",
    "                              max_features =100000,\n",
    "                              token_pattern=None)\n",
    "\n",
    "tfidf_bigrams =  TfidfVectorizer(analyzer='word',\n",
    "                              tokenizer=dummy_fun,\n",
    "                              preprocessor=dummy_fun,\n",
    "                              max_features =100000,\n",
    "                              token_pattern=None, ngram_range=(1,2))\n",
    "\n",
    "tfidf_trigrams =  TfidfVectorizer(analyzer='word',\n",
    "                              tokenizer=dummy_fun,\n",
    "                              preprocessor=dummy_fun,\n",
    "                              max_features =100000,\n",
    "                              token_pattern=None, ngram_range=(1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_list = [cv_unigrams, cv_bigrams, cv_trigrams, tfidf_unigrams, tfidf_bigrams, tfidf_trigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\"def batch_generator(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].toarray()\n",
    "        y_batch = y_data[y_data.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield X_batch,y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            counter=0\"\"\"\n",
    "\n",
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0]/batch_size\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\johns\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=100000))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv_unigrams.fit_transform(df['review']) \n",
    "y = np.array(df['sentiment'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\johns\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "4800/4800 [==============================] - 4s 790us/sample - loss: 0.3109 - acc: 0.8673\n",
      "768/768 [==============================] - 113s 147ms/step - loss: 0.3650 - acc: 0.8415 - val_loss: 0.3109 - val_acc: 0.8673\n",
      "Epoch 2/5\n",
      "4800/4800 [==============================] - 4s 749us/sample - loss: 0.4615 - acc: 0.8540\n",
      "768/768 [==============================] - 111s 145ms/step - loss: 0.0836 - acc: 0.9694 - val_loss: 0.4615 - val_acc: 0.8540\n",
      "Epoch 3/5\n",
      "4800/4800 [==============================] - 4s 905us/sample - loss: 0.7913 - acc: 0.8475\n",
      "768/768 [==============================] - 114s 149ms/step - loss: 0.0136 - acc: 0.9954 - val_loss: 0.7913 - val_acc: 0.8475\n",
      "Epoch 4/5\n",
      "356/768 [============>.................] - ETA: 59s - loss: 0.0019 - acc: 0.9996"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-66236d1d93b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit_generator(generator=batch_generator(X_train, y_train, 25, True),\n\u001b[0;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                     steps_per_epoch= 768)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=batch_generator(X_train, y_train, 25, True),\n",
    "                    epochs=5, validation_data=(X_validation.todense(), y_validation),\n",
    "                    steps_per_epoch= 768)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "def test_all_accuracy(vectorizer_list, reviews, sentiment):\n",
    "    score_list = list()\n",
    "    cm_list = list()\n",
    "    f1_list = list()\n",
    "    y = np.array(sentiment)\n",
    "    for vec in vectorizer_list:\n",
    "        X = vec.fit_transform(reviews)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, activation='relu', input_dim=100000))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit_generator(generator=batch_generator(X_train, y_train, 25, True),\n",
    "                    epochs=2, validation_data=(X_validation.todense(), y_validation),\n",
    "                    steps_per_epoch= 768)\n",
    "        prediction = model.predict_classes(X_test)\n",
    "        \n",
    "        score_list.append(accuracy_score(y_test, prediction))\n",
    "        f1_list.append(f1_score(y_test, prediction))\n",
    "        cm_list.append(confusion_matrix(y_test, prediction))\n",
    "    return score_list, cm_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 818us/sample - loss: 0.3183 - acc: 0.8615\n",
      "768/768 [==============================] - 115s 149ms/step - loss: 0.3625 - acc: 0.8457 - val_loss: 0.3183 - val_acc: 0.8615\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 755us/sample - loss: 0.4235 - acc: 0.8550\n",
      "768/768 [==============================] - 117s 153ms/step - loss: 0.0761 - acc: 0.9718 - val_loss: 0.4235 - val_acc: 0.8550\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 808us/sample - loss: 0.3020 - acc: 0.8717\n",
      "768/768 [==============================] - 113s 147ms/step - loss: 0.3454 - acc: 0.8527 - val_loss: 0.3020 - val_acc: 0.8717\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 770us/sample - loss: 0.5600 - acc: 0.8585\n",
      "768/768 [==============================] - 115s 150ms/step - loss: 0.0317 - acc: 0.9884 - val_loss: 0.5600 - val_acc: 0.8585\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 813us/sample - loss: 0.2897 - acc: 0.8731\n",
      "768/768 [==============================] - 113s 147ms/step - loss: 0.3491 - acc: 0.8508 - val_loss: 0.2897 - val_acc: 0.8731\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 752us/sample - loss: 0.5374 - acc: 0.8602\n",
      "768/768 [==============================] - 112s 146ms/step - loss: 0.0327 - acc: 0.9886 - val_loss: 0.5374 - val_acc: 0.8602\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 813us/sample - loss: 0.2946 - acc: 0.8758\n",
      "768/768 [==============================] - 120s 157ms/step - loss: 0.3606 - acc: 0.8454 - val_loss: 0.2946 - val_acc: 0.8758\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 750us/sample - loss: 0.3669 - acc: 0.8596\n",
      "768/768 [==============================] - 112s 146ms/step - loss: 0.0640 - acc: 0.9783 - val_loss: 0.3669 - val_acc: 0.8596\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 818us/sample - loss: 0.2852 - acc: 0.8813\n",
      "768/768 [==============================] - 113s 147ms/step - loss: 0.3471 - acc: 0.8493 - val_loss: 0.2852 - val_acc: 0.8813\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 752us/sample - loss: 0.3726 - acc: 0.8733\n",
      "768/768 [==============================] - 112s 146ms/step - loss: 0.0293 - acc: 0.9907 - val_loss: 0.3726 - val_acc: 0.8733\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 813us/sample - loss: 0.2839 - acc: 0.8796\n",
      "768/768 [==============================] - 112s 146ms/step - loss: 0.3456 - acc: 0.8541 - val_loss: 0.2839 - val_acc: 0.8796\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 870us/sample - loss: 0.3751 - acc: 0.8750\n",
      "768/768 [==============================] - 113s 148ms/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.3751 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "score_list, f1_list, cm_list = test_all_accuracy(vec_list, df['review'], df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8508333333333333,\n",
       " 0.86,\n",
       " 0.857,\n",
       " 0.8503333333333334,\n",
       " 0.8641666666666666,\n",
       " 0.8723333333333333]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vec = [tfidf_bigrams, tfidf_trigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_list = [20,30,40,50,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_hidden(vectorizer_list, hidden_list, reviews, sentiment):\n",
    "    score_list = list()\n",
    "    cm_list = list()\n",
    "    f1_list = list()\n",
    "    y = np.array(sentiment)\n",
    "    for vec in vectorizer_list:\n",
    "        X = vec.fit_transform(reviews)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
    "        \n",
    "        for n_hidden in hidden_list:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(n_hidden, activation='relu', input_dim=100000))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            history = model.fit_generator(generator=batch_generator(X_train, y_train, 25, True),\n",
    "                        epochs=2, validation_data=(X_validation.todense(), y_validation),\n",
    "                        steps_per_epoch= 768)\n",
    "            prediction = model.predict_classes(X_test)\n",
    "\n",
    "            score_list.append(accuracy_score(y_test, prediction))\n",
    "            f1_list.append(f1_score(y_test, prediction))\n",
    "            cm_list.append(confusion_matrix(y_test, prediction))\n",
    "            \n",
    "    return score_list, cm_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_two_hidden(vectorizer_list, hidden_list, reviews, sentiment):\n",
    "    score_list = list()\n",
    "    cm_list = list()\n",
    "    f1_list = list()\n",
    "    y = np.array(sentiment)\n",
    "    for vec in vectorizer_list:\n",
    "        X = vec.fit_transform(reviews)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
    "        \n",
    "        for n_hidden in hidden_list:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(n_hidden[0], activation='relu', input_dim=100000))\n",
    "            model.add(Dense(n_hidden[1], activation='relu'))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            history = model.fit_generator(generator=batch_generator(X_train, y_train, 25, True),\n",
    "                        epochs=2, validation_data=(X_validation.todense(), y_validation),\n",
    "                        steps_per_epoch= 768)\n",
    "            prediction = model.predict_classes(X_test)\n",
    "\n",
    "            score_list.append(accuracy_score(y_test, prediction))\n",
    "            f1_list.append(f1_score(y_test, prediction))\n",
    "            cm_list.append(confusion_matrix(y_test, prediction))\n",
    "            \n",
    "    return score_list, cm_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 3s 643us/sample - loss: 0.3005 - acc: 0.8823\n",
      "768/768 [==============================] - 30s 39ms/step - loss: 0.4426 - acc: 0.8442 - val_loss: 0.3005 - val_acc: 0.8823\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 2s 471us/sample - loss: 0.2786 - acc: 0.8835\n",
      "768/768 [==============================] - 28s 36ms/step - loss: 0.1184 - acc: 0.9727 - val_loss: 0.2786 - val_acc: 0.8835\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 3s 670us/sample - loss: 0.2885 - acc: 0.8850\n",
      "768/768 [==============================] - 42s 55ms/step - loss: 0.4125 - acc: 0.8520 - val_loss: 0.2885 - val_acc: 0.8850\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 2s 500us/sample - loss: 0.2839 - acc: 0.8804\n",
      "768/768 [==============================] - 36s 46ms/step - loss: 0.0933 - acc: 0.9782 - val_loss: 0.2839 - val_acc: 0.8804\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 3s 631us/sample - loss: 0.2822 - acc: 0.8860\n",
      "768/768 [==============================] - 48s 62ms/step - loss: 0.3934 - acc: 0.8602 - val_loss: 0.2822 - val_acc: 0.8860\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - ETA: 0s - loss: 0.2877 - acc: 0.882 - 3s 535us/sample - loss: 0.2874 - acc: 0.8825\n",
      "768/768 [==============================] - 45s 59ms/step - loss: 0.0755 - acc: 0.9815 - val_loss: 0.2874 - val_acc: 0.8825\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 776us/sample - loss: 0.2787 - acc: 0.8838\n",
      "768/768 [==============================] - 55s 72ms/step - loss: 0.3859 - acc: 0.8537 - val_loss: 0.2787 - val_acc: 0.8838\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 583us/sample - loss: 0.2886 - acc: 0.8773\n",
      "768/768 [==============================] - 53s 69ms/step - loss: 0.0683 - acc: 0.9837 - val_loss: 0.2886 - val_acc: 0.8773\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 3s 671us/sample - loss: 0.2821 - acc: 0.8821\n",
      "768/768 [==============================] - 62s 81ms/step - loss: 0.3789 - acc: 0.8578 - val_loss: 0.2821 - val_acc: 0.8821\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 609us/sample - loss: 0.3116 - acc: 0.8733\n",
      "768/768 [==============================] - 61s 80ms/step - loss: 0.0594 - acc: 0.9861 - val_loss: 0.3116 - val_acc: 0.8733\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 3s 565us/sample - loss: 0.2974 - acc: 0.8883\n",
      "768/768 [==============================] - 28s 37ms/step - loss: 0.4424 - acc: 0.8354 - val_loss: 0.2974 - val_acc: 0.8883\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 522us/sample - loss: 0.2691 - acc: 0.8877\n",
      "768/768 [==============================] - 30s 39ms/step - loss: 0.1195 - acc: 0.9732 - val_loss: 0.2691 - val_acc: 0.8877\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 3s 634us/sample - loss: 0.2807 - acc: 0.8906\n",
      "768/768 [==============================] - 42s 54ms/step - loss: 0.4152 - acc: 0.8463 - val_loss: 0.2807 - val_acc: 0.8906\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 594us/sample - loss: 0.2736 - acc: 0.8879\n",
      "768/768 [==============================] - 39s 51ms/step - loss: 0.0942 - acc: 0.9780 - val_loss: 0.2736 - val_acc: 0.8879\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 3s 626us/sample - loss: 0.2757 - acc: 0.8890\n",
      "768/768 [==============================] - 49s 64ms/step - loss: 0.3980 - acc: 0.8542 - val_loss: 0.2757 - val_acc: 0.8890\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 593us/sample - loss: 0.2790 - acc: 0.8844\n",
      "768/768 [==============================] - 49s 64ms/step - loss: 0.0771 - acc: 0.9821 - val_loss: 0.2790 - val_acc: 0.8844\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 3s 660us/sample - loss: 0.2711 - acc: 0.8908\n",
      "768/768 [==============================] - 57s 75ms/step - loss: 0.3862 - acc: 0.8520 - val_loss: 0.2711 - val_acc: 0.8908\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 648us/sample - loss: 0.2833 - acc: 0.8819\n",
      "768/768 [==============================] - 57s 74ms/step - loss: 0.0668 - acc: 0.9849 - val_loss: 0.2833 - val_acc: 0.8819\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 754us/sample - loss: 0.2692 - acc: 0.8885\n",
      "768/768 [==============================] - 68s 89ms/step - loss: 0.3831 - acc: 0.8538 - val_loss: 0.2692 - val_acc: 0.8885\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 717us/sample - loss: 0.2856 - acc: 0.8865\n",
      "768/768 [==============================] - 65s 85ms/step - loss: 0.0646 - acc: 0.9833 - val_loss: 0.2856 - val_acc: 0.8865\n"
     ]
    }
   ],
   "source": [
    "score_list, f1_list, cm_list = test_one_hidden(small_vec, hidden_list, df['review'], df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 779us/sample - loss: 0.2832 - acc: 0.8815\n",
      "768/768 [==============================] - 38s 50ms/step - loss: 0.3799 - acc: 0.8577 - val_loss: 0.2832 - val_acc: 0.8815\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 698us/sample - loss: 0.3227 - acc: 0.8750s - loss: 0.331\n",
      "768/768 [==============================] - 36s 47ms/step - loss: 0.0525 - acc: 0.9846 - val_loss: 0.3227 - val_acc: 0.8750\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 807us/sample - loss: 0.2940 - acc: 0.8794s - loss: 0.2969 - acc: 0.\n",
      "768/768 [==============================] - 48s 62ms/step - loss: 0.3642 - acc: 0.8572 - val_loss: 0.2940 - val_acc: 0.8794\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 756us/sample - loss: 0.3325 - acc: 0.8740\n",
      "768/768 [==============================] - 47s 62ms/step - loss: 0.0426 - acc: 0.9882 - val_loss: 0.3325 - val_acc: 0.8740\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 933us/sample - loss: 0.2886 - acc: 0.8810\n",
      "768/768 [==============================] - 58s 75ms/step - loss: 0.3665 - acc: 0.8408 - val_loss: 0.2886 - val_acc: 0.8810\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 757us/sample - loss: 0.3354 - acc: 0.8727\n",
      "768/768 [==============================] - 56s 73ms/step - loss: 0.0427 - acc: 0.9869 - val_loss: 0.3354 - val_acc: 0.8727\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 5s 965us/sample - loss: 0.2930 - acc: 0.8771\n",
      "768/768 [==============================] - 76s 99ms/step - loss: 0.3471 - acc: 0.8554 - val_loss: 0.2930 - val_acc: 0.8771\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 5s 1ms/sample - loss: 0.3695 - acc: 0.8683\n",
      "768/768 [==============================] - 78s 101ms/step - loss: 0.0322 - acc: 0.9901 - val_loss: 0.3695 - val_acc: 0.8683\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 6s 1ms/sample - loss: 0.3006 - acc: 0.8725\n",
      "768/768 [==============================] - 129s 168ms/step - loss: 0.3461 - acc: 0.8505 - val_loss: 0.3006 - val_acc: 0.8725\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 5s 990us/sample - loss: 0.3894 - acc: 0.8648\n",
      "768/768 [==============================] - 126s 164ms/step - loss: 0.0285 - acc: 0.9913 - val_loss: 0.3894 - val_acc: 0.8648\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 783us/sample - loss: 0.2747 - acc: 0.8885\n",
      "768/768 [==============================] - 38s 50ms/step - loss: 0.3781 - acc: 0.8527 - val_loss: 0.2747 - val_acc: 0.8885\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 3s 726us/sample - loss: 0.3006 - acc: 0.8848\n",
      "768/768 [==============================] - 40s 52ms/step - loss: 0.0522 - acc: 0.9849 - val_loss: 0.3006 - val_acc: 0.8848\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 845us/sample - loss: 0.2759 - acc: 0.8871\n",
      "768/768 [==============================] - 49s 64ms/step - loss: 0.3676 - acc: 0.8515 - val_loss: 0.2759 - val_acc: 0.8871\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 768us/sample - loss: 0.3208 - acc: 0.8806\n",
      "768/768 [==============================] - 48s 63ms/step - loss: 0.0431 - acc: 0.9880 - val_loss: 0.3208 - val_acc: 0.8806\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 5s 1ms/sample - loss: 0.2774 - acc: 0.8873\n",
      "768/768 [==============================] - 57s 75ms/step - loss: 0.3628 - acc: 0.8491 - val_loss: 0.2774 - val_acc: 0.8873\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 754us/sample - loss: 0.3204 - acc: 0.8819\n",
      "768/768 [==============================] - 56s 73ms/step - loss: 0.0426 - acc: 0.9885 - val_loss: 0.3204 - val_acc: 0.8819\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 4s 915us/sample - loss: 0.2790 - acc: 0.8860\n",
      "768/768 [==============================] - 80s 104ms/step - loss: 0.3493 - acc: 0.8493 - val_loss: 0.2790 - val_acc: 0.8860\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 4s 930us/sample - loss: 0.3413 - acc: 0.8783\n",
      "768/768 [==============================] - 79s 103ms/step - loss: 0.0346 - acc: 0.9900 - val_loss: 0.3413 - val_acc: 0.8783\n",
      "Epoch 1/2\n",
      "4800/4800 [==============================] - 6s 1ms/sample - loss: 0.2839 - acc: 0.8785\n",
      "768/768 [==============================] - 137s 179ms/step - loss: 0.3468 - acc: 0.8504 - val_loss: 0.2839 - val_acc: 0.8785\n",
      "Epoch 2/2\n",
      "4800/4800 [==============================] - 5s 1ms/sample - loss: 0.3796 - acc: 0.8740\n",
      "768/768 [==============================] - 132s 171ms/step - loss: 0.0264 - acc: 0.9908 - val_loss: 0.3796 - val_acc: 0.8740\n"
     ]
    }
   ],
   "source": [
    "hidden_list2 = [(20,10), (30,15), (40,20),(64,32), (128, 64)]\n",
    "score_list2, f1_list2, cm_list2 = test_two_hidden(small_vec, hidden_list2, df['review'], df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8733333333333333,\n",
       " 0.868,\n",
       " 0.8705,\n",
       " 0.8663333333333333,\n",
       " 0.8653333333333333,\n",
       " 0.8741666666666666,\n",
       " 0.8716666666666667,\n",
       " 0.8723333333333333,\n",
       " 0.868,\n",
       " 0.8618333333333333]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.879,\n",
       " 0.8811666666666667,\n",
       " 0.8811666666666667,\n",
       " 0.8765,\n",
       " 0.8711666666666666,\n",
       " 0.8795,\n",
       " 0.8795,\n",
       " 0.8745,\n",
       " 0.8765,\n",
       " 0.8791666666666667]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 40)                4000040   \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 4,000,081\n",
      "Trainable params: 4,000,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MLP = Sequential()\n",
    "MLP.add(Dense(40, activation='relu', input_dim=100000))\n",
    "MLP.add(Dense(1, activation='sigmoid'))\n",
    "MLP.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "MLP.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8830541237113402,\n",
       " 0.8859382498800192,\n",
       " 0.8840838887985694,\n",
       " 0.8784249384741591,\n",
       " 0.8792753396845229,\n",
       " 0.8846706013718296,\n",
       " 0.8841531805800353,\n",
       " 0.8783718300759167,\n",
       " 0.8815726386447178,\n",
       " 0.8819410519459372]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_bigrams.fit_transform(df['review'])\n",
    "y = np.array(df['sentiment'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2400/2400 [==============================] - 2s 968us/sample - loss: 0.2829 - acc: 0.8817\n",
      "768/768 [==============================] - 52s 68ms/step - loss: 0.3983 - acc: 0.8493 - val_loss: 0.2829 - val_acc: 0.8817\n",
      "Epoch 2/2\n",
      "2400/2400 [==============================] - 2s 767us/sample - loss: 0.2745 - acc: 0.8875\n",
      "768/768 [==============================] - 56s 73ms/step - loss: 0.1037 - acc: 0.9688 - val_loss: 0.2745 - val_acc: 0.8875\n"
     ]
    }
   ],
   "source": [
    "MLP = Sequential()\n",
    "MLP.add(Dense(40, activation='relu', input_dim=100000))\n",
    "MLP.add(Dense(1, activation='sigmoid'))\n",
    "MLP.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = MLP.fit_generator(generator=batch_generator(X_train, y_train, 25, True),\n",
    "                        epochs=2, validation_data=(X_validation.todense(), y_validation),\n",
    "                        steps_per_epoch= 768)\n",
    "prediction = MLP.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2612,  335],\n",
       "       [ 353, 2700]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(prediction, y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Actual')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='g')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8853333333333333"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8869908015768726"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
